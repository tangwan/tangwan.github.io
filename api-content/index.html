{"posts":[{"title":"Java公平锁和非公平锁加锁流程","content":"在Java中，ReentrantLock 提供了公平锁和非公平锁两种模式。它们的加锁流程有所不同，主要体现在线程获取锁的顺序上。下面我会用 流程图 和 文字说明 来详细解释这两种锁的加锁流程。 1. 公平锁（Fair Lock） 公平锁的特点是按照线程请求锁的顺序来分配锁，即先到先得。它的加锁流程如下： 流程说明： 线程尝试获取锁。 如果锁空闲，检查是否有其他线程在等待队列中： 如果没有等待队列，当前线程直接获取锁。 如果有等待队列，当前线程加入队列尾部，等待被唤醒。 如果锁被占用，当前线程加入等待队列尾部，等待被唤醒。 当锁释放时，队列中的第一个线程会被唤醒并尝试获取锁。 2. 非公平锁（Non-Fair Lock） 非公平锁的特点是线程可以直接尝试获取锁，而不考虑等待队列的顺序。它的加锁流程如下： 流程说明： 线程尝试获取锁。 如果锁空闲，直接尝试获取锁： 如果获取成功，线程继续执行。 如果获取失败（例如被其他线程抢先），线程加入等待队列尾部。 如果锁被占用，线程直接加入等待队列尾部，等待被唤醒。 当锁释放时，队列中的线程会被唤醒并尝试获取锁，但新来的线程也可以直接尝试获取锁，可能导致“插队”现象。 3. 公平锁 vs 非公平锁的区别 特性 公平锁 非公平锁 获取锁的顺序 严格按照等待队列的顺序（先到先得） 允许插队，新线程可能直接获取锁 性能 较低，因为需要维护队列顺序 较高，减少了线程切换的开销 适用场景 需要严格公平性的场景 对性能要求较高的场景 4. 代码示例 以下是使用 ReentrantLock 的公平锁和非公平锁的示例： import java.util.concurrent.locks.ReentrantLock; public class LockExample { public static void main(String[] args) { // 公平锁 ReentrantLock fairLock = new ReentrantLock(true); // 非公平锁 ReentrantLock nonFairLock = new ReentrantLock(false); Runnable task = () -&gt; { fairLock.lock(); // 或 nonFairLock.lock() try { System.out.println(Thread.currentThread().getName() + &quot; 获取锁&quot;); Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } finally { fairLock.unlock(); // 或 nonFairLock.unlock() System.out.println(Thread.currentThread().getName() + &quot; 释放锁&quot;); } }; Thread t1 = new Thread(task, &quot;Thread-1&quot;); Thread t2 = new Thread(task, &quot;Thread-2&quot;); Thread t3 = new Thread(task, &quot;Thread-3&quot;); t1.start(); t2.start(); t3.start(); } } 5. 总结 公平锁：保证线程获取锁的顺序，但性能较低。 非公平锁：允许线程插队，性能较高，但可能导致某些线程长时间等待。 根据具体场景选择合适的锁模式，可以更好地平衡公平性和性能。 ","link":"https://tangwan.github.io/post/java-gong-ping-suo-he-fei-gong-ping-suo-jia-suo-liu-cheng/"},{"title":"mysql 判断表字段是否存在,不存在则添加该字段","content":"需要使用存储过程来实现 -- 如果存在就删除该储存过程 drop procedure if exists add_my_column; -- 编写储存过程需要修改语句结束符为$$（字符自定义） delimiter $$ create procedure add_my_column() begin if not exists(select * from information_schema.`COLUMNS` where table_schema = 'my_database' and TABLE_NAME = 'my_table' and COLUMN_NAME = 'xxx') then ALTER TABLE `my_table` ADD COLUMN `xxx` bigint(12) DEFAULT NULL COMMENT 'xxx'; end if; end$$ -- 储存过程语句完结后需要把分割符改回原来的分号 delimiter ; call add_my_column(); -- 执行储存过程 drop procedure if exists add_my_column;-- 如果存在就删除该储存过程 ","link":"https://tangwan.github.io/post/mysql-pan-duan-biao-zi-duan-shi-fou-cun-zai-bu-cun-zai-ze-tian-jia-gai-zi-duan/"},{"title":"istio模拟灰度发布","content":"istio功能简介 Istio是一个开源的服务网格平台，用于管理和连接容器化应用程序的微服务。它提供了一系列功能，包括： 流量管理：Istio可以控制和路由应用程序的流量，实现灰度发布、A/B测试、故障恢复等功能。 安全性：Istio提供了强大的安全功能，包括身份认证、授权、访问控制和加密通信，以保护应用程序的安全性。 观察性：Istio可以收集和展示应用程序的运行时数据，如请求流量、延迟、错误率等，帮助开发人员进行故障排查和性能优化。 策略和配额：Istio允许定义和实施各种策略和配额，如限制每秒请求数、设置访问控制规则等。 故障注入和测试：Istio提供了故障注入的功能，可以模拟网络延迟、错误响应等情况，以测试应用程序的容错能力。 总之，Istio可以帮助开发人员更好地管理和监控微服务架构，提供更好的安全性、可观察性和流量控制能力。 下面使用官方文档的例子做验证，所有资源文件部署在defaultnamespace下 模拟部分流量管理功能 给命名空间添加标签 # 指示 Istio 在部署应用的时候，自动注入 Envoy 边车代理 $ kubectl label namespace default istio-injection=enabled 部署istio gateway，作为流量入口，一个k8s集群只需要一个网关 bookinfo-gateway.yaml apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: bookinfo-gateway spec: # The selector matches the ingress gateway pod labels. # If you installed Istio using Helm following the standard documentation, this would be &quot;istio=ingress&quot; selector: istio: ingressgateway # use istio default controller servers: - port: number: 80 name: http protocol: HTTP #如果配置具体域名，需要通过域名访问，域名可在本机hosts配置，如果配置*则可用ip或域名访问 hosts: - &quot;*&quot; --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: bookinfo spec: hosts: - &quot;*&quot; gateways: - bookinfo-gateway http: - match: - uri: exact: /productpage - uri: prefix: /static - uri: exact: /login - uri: exact: /logout - uri: prefix: /api/v1/products route: - destination: host: productpage port: number: 9080 $ kubectl apply -f bookinfo-gateway.yaml 部署bookinfo应用 bookinfo.yaml # Copyright Istio Authors # # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ################################################################################################## # This file defines the services, service accounts, and deployments for the Bookinfo sample. # # To apply all 4 Bookinfo services, their corresponding service accounts, and deployments: # # kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml # # Alternatively, you can deploy any resource separately: # # kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -l service=reviews # reviews Service # kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -l account=reviews # reviews ServiceAccount # kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -l app=reviews,version=v3 # reviews-v3 Deployment ################################################################################################## ################################################################################################## # Details service ################################################################################################## apiVersion: v1 kind: Service metadata: name: details labels: app: details service: details spec: ports: - port: 9080 name: http selector: app: details --- apiVersion: v1 kind: ServiceAccount metadata: name: bookinfo-details labels: account: details --- apiVersion: apps/v1 kind: Deployment metadata: name: details-v1 labels: app: details version: v1 spec: replicas: 1 selector: matchLabels: app: details version: v1 template: metadata: labels: app: details version: v1 spec: serviceAccountName: bookinfo-details containers: - name: details image: docker.io/istio/examples-bookinfo-details-v1:1.18.0 imagePullPolicy: IfNotPresent ports: - containerPort: 9080 --- ################################################################################################## # Ratings service ################################################################################################## apiVersion: v1 kind: Service metadata: name: ratings labels: app: ratings service: ratings spec: ports: - port: 9080 name: http selector: app: ratings --- apiVersion: v1 kind: ServiceAccount metadata: name: bookinfo-ratings labels: account: ratings --- apiVersion: apps/v1 kind: Deployment metadata: name: ratings-v1 labels: app: ratings version: v1 spec: replicas: 1 selector: matchLabels: app: ratings version: v1 template: metadata: labels: app: ratings version: v1 spec: serviceAccountName: bookinfo-ratings containers: - name: ratings image: docker.io/istio/examples-bookinfo-ratings-v1:1.18.0 imagePullPolicy: IfNotPresent ports: - containerPort: 9080 --- ################################################################################################## # Reviews service ################################################################################################## apiVersion: v1 kind: Service metadata: name: reviews labels: app: reviews service: reviews spec: ports: - port: 9080 name: http selector: app: reviews --- apiVersion: v1 kind: ServiceAccount metadata: name: bookinfo-reviews labels: account: reviews --- apiVersion: apps/v1 kind: Deployment metadata: name: reviews-v1 labels: app: reviews version: v1 spec: replicas: 1 selector: matchLabels: app: reviews version: v1 template: metadata: labels: app: reviews version: v1 spec: serviceAccountName: bookinfo-reviews containers: - name: reviews image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0 imagePullPolicy: IfNotPresent env: - name: LOG_DIR value: &quot;/tmp/logs&quot; ports: - containerPort: 9080 volumeMounts: - name: tmp mountPath: /tmp - name: wlp-output mountPath: /opt/ibm/wlp/output volumes: - name: wlp-output emptyDir: {} - name: tmp emptyDir: {} --- apiVersion: apps/v1 kind: Deployment metadata: name: reviews-v2 labels: app: reviews version: v2 spec: replicas: 1 selector: matchLabels: app: reviews version: v2 template: metadata: labels: app: reviews version: v2 spec: serviceAccountName: bookinfo-reviews containers: - name: reviews image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0 imagePullPolicy: IfNotPresent env: - name: LOG_DIR value: &quot;/tmp/logs&quot; ports: - containerPort: 9080 volumeMounts: - name: tmp mountPath: /tmp - name: wlp-output mountPath: /opt/ibm/wlp/output volumes: - name: wlp-output emptyDir: {} - name: tmp emptyDir: {} --- apiVersion: apps/v1 kind: Deployment metadata: name: reviews-v3 labels: app: reviews version: v3 spec: replicas: 1 selector: matchLabels: app: reviews version: v3 template: metadata: labels: app: reviews version: v3 spec: serviceAccountName: bookinfo-reviews containers: - name: reviews image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0 imagePullPolicy: IfNotPresent env: - name: LOG_DIR value: &quot;/tmp/logs&quot; ports: - containerPort: 9080 volumeMounts: - name: tmp mountPath: /tmp - name: wlp-output mountPath: /opt/ibm/wlp/output volumes: - name: wlp-output emptyDir: {} - name: tmp emptyDir: {} --- ################################################################################################## # Productpage services ################################################################################################## apiVersion: v1 kind: Service metadata: name: productpage labels: app: productpage service: productpage spec: ports: - port: 9080 name: http selector: app: productpage --- apiVersion: v1 kind: ServiceAccount metadata: name: bookinfo-productpage labels: account: productpage --- apiVersion: apps/v1 kind: Deployment metadata: name: productpage-v1 labels: app: productpage version: v1 spec: replicas: 1 selector: matchLabels: app: productpage version: v1 template: metadata: annotations: prometheus.io/scrape: &quot;true&quot; prometheus.io/port: &quot;9080&quot; prometheus.io/path: &quot;/metrics&quot; labels: app: productpage version: v1 spec: serviceAccountName: bookinfo-productpage containers: - name: productpage image: docker.io/istio/examples-bookinfo-productpage-v1:1.18.0 imagePullPolicy: IfNotPresent ports: - containerPort: 9080 volumeMounts: - name: tmp mountPath: /tmp volumes: - name: tmp emptyDir: {} --- $ kubectl apply -f bookinfo.yaml $ kubectl get pods 一个productpage前端和details、ratings、reviews后端接口服务，reviews部署了3个版本 我们现在没有创建任何目标规则，一个请求从gateway--&gt;k8s service--&gt;POD，reviews三个版本labels.app相同， 默认每次请求productpage服务会轮训调用三个版本的reviews # 设置 EXTERNAL-IP 的值之后， 您的环境就有了一个外部的负载均衡器， # 可以将其用作入站网关。 但如果 EXTERNAL-IP 的值为 &lt;none&gt; (或者一直是 &lt;pending&gt; 状态)， # 则您的环境则没有提供可作为入站流量网关的外部负载均衡器。 # 在这个情况下，您还可以用服务（Service）的节点端口访问网关。 $ kubectl get svc istio-ingressgateway -n istio-system # 查看Service IP和应用端口 $ kubectl get svc 我这里有EXTERNAL-IP我就用http://${EXTERNAL-IP}/productpage在浏览器访问， 否则就用http://${CLUSTER-IP}:9080/productpage (需要再集群任意一台机器上访问) 红色框显示当前提供服务的是哪个版本的reviews，多次刷新发现会在 v1 v2 v3之间变化 设置每个版本的子集subsets，可以为不同版本指定不同的负载均衡算法 distination-rule-reviews.yaml apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: reviews spec: host: reviews trafficPolicy: loadBalancer: simple: RANDOM subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 # trafficPolicy: # loadBalancer: # simple: ROUND_ROBIN - name: v3 labels: version: v3 $ kubectl apply -f distination-rule-reviews.yaml 测试-reviews v2和v3版本各50%权重 virtual-service-reviews-v2-v3.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v2 weight: 50 - destination: host: reviews subset: v3 weight: 50 $ kubectl apply -f virtual-service-reviews-v2-v3.yaml 浏览器多次刷新，发现右下角reviews版本在v2 v3之间切换，总体上权重维持1:1 测试-reviews v1和v2版本各权重90:10权重 virtual-service-reviews-90-10.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 weight: 90 - destination: host: reviews subset: v2 weight: 10 $ kubectl apply -f virtual-service-reviews-90-10.yaml 浏览器多次刷新，发现右下角reviews版本在v1 v2之间切换，总体上权重维持9:1 测试-把权重全部给到v3 virtual-service-reviews-v3.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v3 $ kubectl apply -f virtual-service-reviews-v3.yaml 浏览器多次刷新，发现右下角reviews版本保持v3；经过上面5、6、7三个步骤我们就明白了如何控制灰度发布 测试-带有特征的流量转发 有时为了验证新版本需要把带有指定特征的流量导入到新版本，无特征的流量继续访问老版本 virtual-service-reviews-jason-v2-v3.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - match: - headers: end-user: exact: jason route: - destination: host: reviews subset: v2 - route: - destination: host: reviews subset: v3 $ kubectl apply -f virtual-service-reviews-jason-v2-v3.yaml 如果请求头带有end-user:jason，就把流量转到v2版本，否则流量转到v3，这里的exact代表全匹配模式， 还可以指定prefix、正则表达式等支持的匹配模式；此时我们多次刷新页面发现都是v3版本，我们在右上角登录 jason用户（密码可不填），再次刷新页面发现都是v2版本；通过查看productpage服务日志发现请求reviews 接口带了end-user:jason请求头 Istio中的&quot;match&quot;用于定义流量管理规则，以便对特定的请求进行匹配和操作。以下是一些常见的匹配模式： URI匹配：可以基于请求的URI路径进行匹配，例如/api/v1/users/*。 方法匹配：可以基于HTTP方法（GET、POST等）进行匹配。 主机匹配：可以基于请求的主机名进行匹配，例如example.com。 标头匹配：可以基于请求的标头进行匹配，例如x-request-id=123456。 标签匹配：可以基于Kubernetes标签进行匹配，例如version=v1。 端口匹配：可以基于请求的端口号进行匹配。 这些匹配模式可以组合使用，以创建更复杂的匹配规则。例如，可以使用URI匹配和方法匹配来仅匹配特定路径和HTTP方法的请求。Istio的匹配规则非常灵活，可以根据具体的需求进行定制。 应用部署方案 ","link":"https://tangwan.github.io/post/istio-mo-ni-hui-du-fa-bu/"},{"title":"Shell变量嵌套","content":"最近使用gitlab做CI/CD，需要根据当前分支获取不同环境的harbor镜像仓库，当前分支有dev、test、pre、master ，分支和gitlab变量指向如下： 分支 gitlab变量 gitlab 变量值 dev CI_DEV_REGISTRY https://dev-harbor.xxx.com test CI_TEST_REGISTRY https://test-harbor.xxx.com pre CI_PRE_REGISTRY https://pre-harbor.xxx.com master CI_PROD_REGISTRY https://prod-harbor.xxx.com 示例代码: # 默认变量 BRANCH=master # 自定义变量 CI_DEV_REGISTRY=https://dev-harbor.xxx.com CI_PROD_REGISTRY=https://prod-harbor.xxx.com # 转大写(2中方式都可以) ENV=`echo ${BRANCH} | tr '[:lower:]' '[:upper:]'` #ENV=`echo $BRANCH | tr 'a-z' 'A-Z'` if [ &quot;$BRANCH&quot;x = &quot;master&quot;x ]; then ENV=PROD fi REGISTRY=`eval echo '$'&quot;CI_${ENV}_REGISTRY&quot;` echo $REGISTRY ","link":"https://tangwan.github.io/post/shell-bian-liang-qian-tao/"},{"title":"Redisson有哪些锁","content":"Redisson 是一个基于 Redis 的分布式 Java 对象和服务的框架，在 Redisson 中提供了多种类型的锁来实现分布式锁的功能。以下是 Redisson 提供的几种主要的锁类型： 可重入锁（ReentrantLock）：与 Java 的 ReentrantLock 类似，支持可重入特性。即同一个线程可以多次获得该锁，并且需要释放相同次数才能完全释放锁。 公平锁（FairLock）：可重入锁的变体，实现了公平性。当多个请求获取锁时，按照请求的顺序进行排队，保证先请求的先获取锁。 读写锁（ReadWriteLock）：与 Java 的 ReadWriteLock 类似，支持读写分离。多个线程可以同时获取读锁，但只有一个线程可以获取写锁。 联锁（MultiLock）：同时获取多个锁对象，只有当所有锁都成功获取时，才算获取成功。类似于数据库事务中的行锁。 红锁（RedLock）：在分布式环境中实现的一种基于 Redis 的互斥锁算法。通过在不同的 Redis 节点上设置互斥锁，通过多数节点达成共识来获取锁。 信号量（Semaphore）：控制同时访问某个资源的线程数量。可以用于实现限流策略。 可过期性信号量（PermitExpirableSemaphore）: Redisson的可过期性信号量（PermitExpirableSemaphore）实在RSemaphore对象的基础上，为每个信号增加了一个过期时间。每个信号可以通过独立的ID来辨识，释放时只能通过提交这个ID才能释放。 闭锁（CountDownLatch）: Redisson的分布式闭锁（CountDownLatch）Java对象RCountDownLatch采用了与java.util.concurrent.CountDownLatch相似的接口和用法。 以上是 Redisson 提供的几种常见的锁类型，每种锁都有不同的应用场景和特点，可以根据具体的需求选择适合的锁类型来实现分布式锁。此外，Redisson 还提供了其他功能强大的分布式对象和服务，如分布式集合、分布式 Map、分布式任务等。 参考： Redisson 几种锁 ","link":"https://tangwan.github.io/post/redisson-you-na-xie-suo/"},{"title":"Java元数据空间存储的是什么","content":"在 Java 中，元数据空间（Metaspace）存储的是类的元数据信息。元数据指的是描述类结构、方法、字段等信息的数据。 在传统的 Java 虚拟机（JVM）中，类的元数据信息通常存储在永久代（PermGen）中。但是，自从 JDK 8 开始，永久代被元数据空间取代。元数据空间是一块由操作系统管理的本地内存区域，它不再受到虚拟机的堆内存限制，并且可以动态地调整大小。 元数据空间存储的内容包括： 类的结构信息：包括类的名称、父类、接口、字段、方法等。 字节码：即类的编译后的字节码指令，用于在虚拟机中执行。 静态变量：静态变量属于类级别的变量，在元数据空间中存储静态变量的初始值和引用。 符号引用：类的符号引用指向类的符号地址，用于在运行时解析成直接引用。 注解信息：类、方法、字段上的注解信息，用于提供额外的元数据。 定义的枚举类型：枚举类型及其成员在元数据空间中进行存储。 通过将类的元数据信息存储在元数据空间中，Java 虚拟机可以更加灵活地管理和调整类的元数据大小，提高系统的稳定性和可扩展性。同时，元数据空间的引入也使得开发者可以更好地管理和控制类的元数据信息，例如通过 JVM 参数来调整元数据空间的大小。 需要注意的是，具体的元数据存储方式和实现可能因不同的 Java 虚拟机实现而有所差异。以上内容是一般情况下元数据空间的存储内容。 ","link":"https://tangwan.github.io/post/java-yuan-shu-ju-kong-jian-cun-chu-de-shi-shi-me/"},{"title":"MySQL 执行一条 SQL 语句的流程","content":"MySQL 执行一条 SQL 语句的流程主要包括以下几个步骤： 语法分析（Parsing）：MySQL 对输入的 SQL 语句进行语法分析，检查语句是否符合语法规则，并将其转换为内部数据结构。 词法分析（Lexical Analysis）：MySQL 对语句进行词法分析，将 SQL 语句按照关键字、标识符、运算符等进行划分，形成一个词法单元序列。 查询优化器（Query Optimization）：MySQL 使用查询优化器分析 SQL 语句，根据统计信息和索引等优化策略生成多个可能的执行计划，并估算每个执行计划的成本，选择最优的执行计划。 执行计划生成（Execution Plan Generation）：MySQL 根据查询优化器的选择，生成实际的执行计划（Execution Plan），包括确定表的连接顺序、使用索引的方式、选择合适的算法等。 执行计划执行（Execution）：MySQL 执行生成的执行计划，从存储引擎中读取数据，进行排序、聚合、连接等操作，生成最终的结果集。 结果返回（Result Return）：MySQL 将执行得到的结果返回给客户端，完成整个 SQL 语句的执行过程。 需要注意的是，MySQL 的执行流程是一个高度复杂的过程，其中涉及到多个组件和算法的配合工作，以及对表结构、索引、统计信息等的综合考虑。此外，MySQL 还会对一些常用的 SQL 语句进行缓存，以提高执行效率。具体的执行流程会根据实际情况和 MySQL 版本的不同而有所差异。 ","link":"https://tangwan.github.io/post/mysql-zhi-xing-yi-tiao-sql-yu-ju-de-liu-cheng/"},{"title":"MySQL的MVCC","content":"MySQL的MVCC（多版本并发控制）是一种用于处理并发读写操作的机制。它允许多个事务同时读取数据库的一致性视图，而不会相互干扰或产生冲突。 MVCC的原理可以简单地描述为以下几个要点： 每行数据都有一个版本号：在更新数据时，MySQL会为每一行数据分配一个唯一的版本号。这个版本号用于标识数据的修改历史。 读取操作使用快照：当一个事务开始时，它会创建一个快照，记录当前数据库的状态。这个快照包含了事务开始时的所有数据版本号。 读取操作不会阻塞写入操作：当一个事务在读取数据时，即使其他事务正在修改同一行数据，也不会发生阻塞。读取操作会使用快照来获取一致性的数据视图。 写入操作使用行级锁：当一个事务开始修改数据时，MySQL会为相关的行加上行级锁，防止其他事务同时修改同一行数据。这样可以保证数据的一致性和并发性。 事务的隔离级别影响MVCC：MySQL的事务隔离级别（如读未提交、读已提交、可重复读、串行化）会影响MVCC的行为。不同的隔离级别会决定事务能够看到的数据版本范围。 通过MVCC机制，MySQL能够在高并发的情况下提供读写操作的并发性和一致性。它允许事务读取一致性的数据视图，而不会被其他事务的并发修改所干扰。这种机制对于处理并发访问数据库的应用程序非常重要。 ","link":"https://tangwan.github.io/post/mysql-de-mvcc/"},{"title":"清理Mac鼠标右键打开方式中的重复项","content":"问题简介 Edge浏览器升级后，鼠标右键的打开方式中出现了2个Edge，两个图标后面跟了小版本号，但其实电脑只有一个Edge浏览器，其实是打开同一个浏览器。 解决办法 这个问题目前很常见，想要解决这个问题也很简单，只需要一段终端命令，重建该列表就行了。 打开OS X自带的【终端】(可用Spotlight搜索找到)，复制粘贴以下命令并回车： /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister -kill -r -domain local -domain user;killall Finder;echo “Open With has been rebuilt, Finder will relaunch ","link":"https://tangwan.github.io/post/qing-li-mac-shu-biao-you-jian-da-kai-fang-shi-zhong-de-chong-fu-xiang/"},{"title":"使用jdk8请求https的url报错PKIX path building failed","content":"报错内容 javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification pa th to requested target at sun.security.ssl.Alert.createSSLException(Alert.java:131) at sun.security.ssl.TransportContext.fatal(TransportContext.java:370) at sun.security.ssl.TransportContext.fatal(TransportContext.java:313) at sun.security.ssl.TransportContext.fatal(TransportContext.java:308) at sun.security.ssl.CertificateMessage$T12CertificateConsumer.checkServerCerts(CertificateMessage.java:652) at sun.security.ssl.CertificateMessage$T12CertificateConsumer.onCertificate(CertificateMessage.java:471) at sun.security.ssl.CertificateMessage$T12CertificateConsumer.consume(CertificateMessage.java:367) at sun.security.ssl.SSLHandshake.consume(SSLHandshake.java:376) at sun.security.ssl.HandshakeContext.dispatch(HandshakeContext.java:479) at sun.security.ssl.HandshakeContext.dispatch(HandshakeContext.java:457) at sun.security.ssl.TransportContext.dispatch(TransportContext.java:200) at sun.security.ssl.SSLTransport.decode(SSLTransport.java:155) at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1320) at sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1233) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:417) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:389) at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:558) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:201) at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:167) at org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:732) at org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:707) at org.jsoup.helper.HttpConnection.execute(HttpConnection.java:297) at org.jsoup.helper.HttpConnection.get(HttpConnection.java:286) at com.duliday.spider.service.impl.AdministrativeDivisionManager.export(AdministrativeDivisionManager.java:50) at com.duliday.spider.service.impl.AdministrativeDivisionManager$$FastClassBySpringCGLIB$$23edeb39.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:367) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.duliday.spider.service.impl.AdministrativeDivisionManager$$EnhancerBySpringCGLIB$$d74be86b.export(&lt;generated&gt;) at com.duliday.spider.controller.AdministrativeDivisionController.export(AdministrativeDivisionController.java:29) at com.duliday.spider.controller.AdministrativeDivisionController$$FastClassBySpringCGLIB$$9094180d.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.duliday.common.advice.RequestLogAdvice.around(RequestLogAdvice.java:42) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.duliday.spider.controller.AdministrativeDivisionController$$EnhancerBySpringCGLIB$$a8ae852f.export(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.duliday.common.advice.CrossFilter.doFilter(CrossFilter.java:30) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1589) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:750) Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:439) at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:306) at sun.security.validator.Validator.validate(Validator.java:271) at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:312) at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:221) at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:128) at sun.security.ssl.CertificateMessage$T12CertificateConsumer.checkServerCerts(CertificateMessage.java:636) ... 112 common frames omitted Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141) at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126) at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280) at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:434) ... 118 common frames omitted Mac下解决办法 Chrome下载网站的证书 使用命令导入证书 重启IDEA、重启应用 sudo keytool -import -trustcacerts -keystore /Library/Java/JavaVirtualMachines/jdk1.8.0_361.jdk/Contents/Home/jre/lib/security/cacerts -storepass changeit -noprompt -alias xxxcert -file ~/Downloads/xxx.cer ","link":"https://tangwan.github.io/post/shi-yong-jdk8-qing-qiu-https-de-url-bao-cuo-pkix-path-building-failed/"},{"title":"LinkedHashMap 使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用(LRU)顺序","content":"在 Java 的 LinkedHashMap 中，元素的顺序是基于插入顺序或访问顺序来维护的，具体取决于构造 LinkedHashMap 对象时所使用的构造方法。 默认情况下，LinkedHashMap 使用插入顺序来维护元素的顺序。这意味着元素会按照它们被插入到 LinkedHashMap 中的顺序进行迭代和访问。 当使用带有 accessOrder 参数的构造方法时，LinkedHashMap 将使用访问顺序来维护元素的顺序。 通过将 accessOrder 参数设置为 true，你可以启用访问顺序。在访问顺序模式下，每次访问一个元素（包括获取或更新操作）会将该元素移到链表末尾，使得最近访问的元素位于链表末尾。 需要注意的是，无论使用插入顺序还是访问顺序，LinkedHashMap 内部都使用哈希表来存储键值对。 链表结构只是用来维护元素的顺序。 以下是一个示例： import java.util.LinkedHashMap; public class LinkedHashMapExample { public static void main(String[] args) { // 使用插入顺序创建 LinkedHashMap LinkedHashMap&lt;Integer, String&gt; linkedHashMap = new LinkedHashMap&lt;&gt;(); linkedHashMap.put(3, &quot;C&quot;); linkedHashMap.put(1, &quot;A&quot;); linkedHashMap.put(2, &quot;B&quot;); System.out.println(linkedHashMap); // 输出：{3=C, 1=A, 2=B} // 使用访问顺序创建 LinkedHashMap LinkedHashMap&lt;Integer, String&gt; accessOrderedMap = new LinkedHashMap&lt;&gt;(16, 0.75f, true); accessOrderedMap.put(3, &quot;C&quot;); accessOrderedMap.put(1, &quot;A&quot;); accessOrderedMap.put(2, &quot;B&quot;); System.out.println(accessOrderedMap); // 输出：{3=C, 1=A, 2=B} // 进行一些访问操作 accessOrderedMap.get(2); accessOrderedMap.get(1); System.out.println(accessOrderedMap); // 输出：{3=C, 2=B, 1=A} } } 在上述示例中，第一个 LinkedHashMap 使用插入顺序，元素的顺序与插入顺序相同。 第二个 LinkedHashMap 启用了访问顺序，通过访问键为 1 和 2 的元素，这两个元素被移到链表末尾， 因此输出结果：{3=C, 2=B, 1=A}。 ","link":"https://tangwan.github.io/post/linkedhashmap-shi-yong-shuang-xiang-lian-biao-lai-wei-hu-yuan-su-de-shun-xu-shun-xu-wei-cha-ru-shun-xu-huo-zhe-zui-jin-zui-shao-shi-yong-lrushun-xu/"},{"title":"使用python3 Pillow库对图片进行批量压缩","content":"步骤 需要修改原始图片目录 需要修改压缩后输出图片目录 自行修改压缩比例，示例代码这里是压缩到原尺寸1半 安装依赖库 pip install Pillow 修改参数执行代码 import os from PIL import Image import shutil # Folder containing images to compress input_folder = '/Users/tangwan/Downloads/Picture' # Folder to save compressed images output_folder = '/Users/tangwan/Downloads/Picture2' if not os.path.exists(output_folder): os.makedirs(output_folder) for filename in os.listdir(input_folder): if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'): image_path = os.path.join(input_folder, filename) image = Image.open(image_path) # Compress image , set ratio and quality resized_image = image.resize(tuple(x // 2 for x in image.size)) resized_image.save(os.path.join(output_folder, filename), optimize=True, quality=80) #Copy image metadata shutil.copystat(image_path, os.path.join(output_folder, filename)) print('Images compressed successfully!') ","link":"https://tangwan.github.io/post/shi-yong-python3-pillow-ku-dui-tu-pian-jin-xing-pi-liang-ya-suo/"},{"title":"Java中强引用，弱引用，软引用，虚引用区别","content":"在Java中，强引用、弱引用、软引用和虚引用是用于描述对象引用强度的概念。它们之间的区别如下： 强引用（Strong Reference） 强引用是最常见的引用类型。当一个对象具有强引用时，垃圾回收器不会回收该对象。只有当该对象没有任何强引用时，才会被判定为可回收的垃圾对象。 示例： Object obj = new Object(); // 强引用 弱引用（Weak Reference） 弱引用是一种比较弱的引用类型。当一个对象只有弱引用时，垃圾回收器在进行垃圾回收时会立即回收该对象。弱引用通常用于实现缓存、观察者模式等场景。 示例： WeakReference&lt;Object&gt; weakRef = new WeakReference&lt;&gt;(obj); // 弱引用 软引用（Soft Reference） 软引用是介于强引用和弱引用之间的引用类型。当内存不足时，垃圾回收器会尝试回收软引用对象。与弱引用不同的是，软引用在回收之前会尽可能保持对象存活，只有当内存不足时才会被回收。 示例： SoftReference&lt;Object&gt; softRef = new SoftReference&lt;&gt;(obj); // 软引用 虚引用（Phantom Reference） 虚引用是最弱的引用类型。虚引用的存在主要是为了跟踪对象被垃圾回收的状态。虚引用无法通过引用获取对象，也无法通过虚引用进行对象的操作。它主要用于在对象被回收时收到系统通知或执行特定的清理操作。 示例： PhantomReference&lt;Object&gt; phantomRef = new PhantomReference&lt;&gt;(obj, referenceQueue); // 虚引用 总结： 强引用是最常见的引用类型，只有当没有任何强引用指向一个对象时，对象才会被回收。 弱引用在垃圾回收时会被立即回收。 软引用在内存不足时才会被回收，用于实现缓存等场景。 虚引用无法通过引用获取对象，主要用于跟踪对象被垃圾回收的状态。 ","link":"https://tangwan.github.io/post/java-zhong-qiang-yin-yong-ruo-yin-yong-ruan-yin-yong-xu-yin-yong-qu-bie/"},{"title":"Mac Homebrew安装使用更换国内镜像","content":"简介 Homebrew工具可以看作是mac上的软件包管理器,类似于yum之于centos或redhat和apt-get之于ubuntu，安装软件包会自动安装依赖的软件包，Homebrew 是一款自由及开放源代码的软件包管理系统，用以简化 macOS 和 linux 系统上的软件安装过程。它拥有安装、卸载、更新、查看、搜索等很多实用的功能，通过简单的一条指令，就可以实现包管理，十分方便快捷。Homebrew 主要有四个部分组成: brew、homebrew-core 、homebrew-bottles、homebrew-cask。 名称 说明 brew Homebrew 源代码仓库 homebrew-core Homebrew 核心软件仓库 homebrew-bottles Homebrew 预编译二进制软件包 homebrew-cask 提供 macOS 应用和大型二进制文件 安装 安装homebrew只需要一个命令,可以查看网站，https://brew.sh/index_zh-cn Homebrew GitHub所有仓库地址，https://github.com/Homebrew Homebrew Gitee所有仓库地址，https://gitee.com/brew-cn Homebrew 中科大所有仓库地址，搜索brew，https://mirrors.ustc.edu.cn Homebrew 阿里源所有仓库地址，https://mirrors.aliyun.com/homebrew/ Homebrew 腾讯源所有仓库地址，https://mirrors.cloud.tencent.com/homebrew/ 这么多源随意选一个就可以，网上有些清华大学的源现在好像已经访问不了了，上面的源大家可以收藏一下以备不时之需 # 需要能连接github,国内用户可能会很卡 $ /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; # 可以使用国内代理镜像,国内镜像较多,gitee半小时同步一次github代码库,下面以码云gitee为例 $ curl -sL https://gitee.com/brew-cn/use-brew-cn/raw/master/install.sh | bash - 安装完成后执行下面命令验证命令是否正常，默认安装位置在/usr/local/Homebrew $ brew --version 更换国内源 使用brew安装软件默认从github来下载软件，国内不太稳定，我们可以更换brew下载源为国内的源加速软件安装过程，这里随便选一个吧，我就选阿里的源吧，毕竟大公司不差钱，线路稳定。替换源就是替换默认的brew、brew-core、brew-cast关联的仓库和homebrew-bottles二进制包下载地址。 # 这些仓库默认都是关联的github仓库地址，三个仓库位置可以用下面三个命令查看 $ echo $(brew --repo) $ echo $(brew --repo homebrew/core) $ echo $(brew --repo homebrew/cask) # 查看默认关联的仓库地址 $ cd $(brew --repo) $ git remote -v # 修改这三个仓库关联远程url $ git -C &quot;$(brew --repo)&quot; remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git $ git -C &quot;$(brew --repo homebrew/core)&quot; remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git $ git -C &quot;$(brew --repo homebrew/cask)&quot; remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-cask.git # 替换homebrew-bottles二进制包下载地址为国内地址，就是新增环境变量，如果你已经有了就vim编辑替换url即可 # 如果你使用zsh $ echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles' &gt;&gt; ~/.zshrc $ source ~/.zshrc # 如果你使用bash $ echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles' &gt;&gt; ~/.bash_profile $ source ~/.bash_profile # 刷新源 brew update # 还原为默认的github源 $ git -C &quot;$(brew --repo)&quot; remote set-url origin https://github.com/Homebrew/brew.git $ git -C &quot;$(brew --repo homebrew/core)&quot; remote set-url origin https://github.com/Homebrew/homebrew-core.git $ git -C &quot;$(brew --repo homebrew/cask)&quot; remote set-url origin https://github.com/Homebrew/homebrew-cask.git # 找到 ~/.bash_profile 或者 ~/.zshrc 中的HOMEBREW_BOTTLE_DOMAIN 一行删除 $ brew update 使用 $ brew --help #查看帮助 $ man brew #查看使用手册 # 常用命令 $ brew list #查看已安装的二进制包和桌面应用，Casks为桌面应用列表，Formulae为二进制包列表 # 安装桌面软件 $ brew search another-redis #搜索软件名称 $ brew install another-redis-desktop-manager #安装redis一个优秀的GUI客户端 $ brew reinstall another-redis-desktop-manager #重新安装 $ brew upgrade another-redis-desktop-manager #更新已软件 # 安装非桌面软件 git --version #查看现在的git版本 $ brew install git #安装最新版git $ brew link git #把brew安装的git软链到/usr/local/bin/git $ git --version #查看现在的git版本 # 其他一些常用命令 $ brew update #更新所有已安装的依赖包含homebrew自己 $ brew uninstall xxx1 xxx2 #卸载软件xxx1和xxx2 $ brew list xxx #查看xxx软件的安装位置,不带xxx软件名将列出所有已安装软件 $ brew info git #查看安装的git详细信息，包含依赖的安装项 $ brew config #查看当前brew的配置，包含设置的源 $ brew doctor #检查brew的一些问题，会给出修复建议命令 $ brew cleanup #清理一些过期的链接之类的 $ brew install --verbose --debug FORMULA|CASK #debug安装模式，软件安装出错时可debug安装查看日志 $ brew unlink -n git #查看如果取消软链，哪些文件将被取消软链，-n代表尝试执行，非真正执行 # 开发者工具，用对应的命令+ --help查看用法 $ brew create URL [--no-fetch] #把自己开发的软件包打成brew安装包 $ brew edit [FORMULA|CASK...] # 更多支持的命令 $ brew commands 参考文档 Homebrew Documentation brew update 更新时 shallow clone Mac下brew切换为国内源 Homebrew / Linuxbrew 镜像使用帮助 解决终端compinit:503: no such file or directory: /usr/local/share/zsh/site-functions/_brew_cask ","link":"https://tangwan.github.io/post/mac-homebrew-an-zhuang-shi-yong-geng-huan-guo-nei-jing-xiang/"},{"title":"Java公平锁和非公平锁区别","content":"在Java中，公平锁（Fair Lock）和非公平锁（Nonfair Lock）是用于控制多线程并发访问的锁类型。 它们之间的区别如下： 公平锁 公平锁是指多个线程按照申请锁的顺序来获取锁，即先到先得的原则。 当一个线程释放锁后，等待时间最长的线程将获得锁的访问权。 公平锁的优点是保证了锁的公平性，避免了饥饿现象，所有线程都有机会获取到锁。 但是，公平锁的实现会增加系统的开销，因为需要维护一个线程队列来记录等待锁的线程。 示例： Lock fairLock = new ReentrantLock(true); // 公平锁 非公平锁 非公平锁是指多个线程获取锁的顺序是不确定的，获取锁的机会是随机分配的。 当一个线程释放锁后，下一个获取锁的线程可能是刚刚释放锁的线程，也可能是其他已经在等待队列中的线程。 如果插队线程没有获取到锁，也会进入等待队列排队。非公平锁的优点是可以减少系统开销。 但是，非公平锁可能导致某些线程长时间无法获取到锁，造成饥饿现象。 示例： Lock nonfairLock = new ReentrantLock(false); // 非公平锁 总结 公平锁按照线程申请锁的顺序来获取锁，保证了锁的公平性，但增加了系统开销。 非公平锁的获取锁顺序是不确定的，可以减少系统开销，但可能导致某些线程长时间无法获取到锁。 在性能要求较高的场景下，可以使用非公平锁。而在对锁的公平性要求较高的场景下，可以使用公平锁。 ","link":"https://tangwan.github.io/post/java-gong-ping-suo-he-fei-gong-ping-suo-qu-bie/"},{"title":"Java 线程sleep和wait区别","content":"在Java中，有两种主要的方式来控制线程的暂停：通过Thread类的sleep()方法和通过线程对象的wait()方法。 sleep()方法： Thread.sleep()是Thread类的一个静态方法，用于使当前正在执行的线程暂停指定的时间。 调用Thread.sleep()方法会导致当前线程进入阻塞状态，释放CPU资源，但不会释放锁。 sleep()方法抛出InterruptedException异常，需要进行异常处理。 sleep()方法参数为毫秒数，可以精确控制线程的暂停时间。 wait()方法： wait()方法是Object类的实例方法，用于使当前线程进入等待状态，直到其他线程调用相同对象上的notify()或notifyAll()方法唤醒该线程。 调用wait()方法会导致当前线程释放对应对象的锁，并进入等待队列中等待被唤醒。 在调用wait()方法之前，必须先获得对象的锁，否则会抛出IllegalMonitorStateException异常。 wait()方法必须在synchronized代码块内或方法内调用，因为它依赖于锁机制。 综上所述，sleep()方法用于暂停当前线程一段时间，而wait()方法用于等待其他线程通知并唤醒。sleep()不会释放锁，而wait() 会释放锁并进入等待队列。另外，wait()方法需要在synchronized块中调用，而sleep()方法则不需要。 ","link":"https://tangwan.github.io/post/java-xian-cheng-sleep-he-wait-qu-bie/"},{"title":"Java的ASM是什么技术","content":"ASM（全称为：Abstract Syntax Model）是一个用于分析、修改以及生成Java字节码的库。它提供了一种方式来动态地生成、转换和操作字节码，使开发人员能够在运行时修改Java类的行为。 ASM可以用于很多不同的应用场景，比如字节码增强、AOP（面向切面编程）、代码生成等。它可以让开发者直接操作字节码，从而更加灵活地控制程序的行为，并且在某些情况下可以提高性能。 与其他类似的字节码操作库相比，ASM的特点是轻量级和高性能。它的设计遵循了简单、可扩展、高效的原则，并且提供了丰富的API和组件，使得开发者可以方便地进行字节码分析和修改。 总结来说，ASM是一项技术，用于在Java字节码级别上对类进行分析和修改，提供了灵活、高效的手段来操作字节码。它在实现字节码增强、AOP等领域具有广泛的应用。 ","link":"https://tangwan.github.io/post/java-de-asm-shi-shi-me-ji-zhu/"},{"title":"Java锁升级原理","content":"Java中的锁升级是指在多线程环境下，锁的状态从无锁状态逐渐升级为偏向锁、轻量级锁和重量级锁。这种升级的过程是为了提高并发性能。 偏向锁（Biased Locking）： 偏向锁是为了解决只有一个线程访问同步块时的性能问题。 当一个线程访问同步块时，使用CAS操作将对象头中的线程ID记录下来，表示该对象偏向于这个线程。 如果后续访问同步块的线程仍然是同一个线程，那么不需要加锁，直接进入同步块执行。 如果其他线程访问同步块，偏向锁会自动撤销，升级为轻量级锁。 轻量级锁（Lightweight Locking）： 轻量级锁是为了解决多个线程交替访问同步块的性能问题。 当第一个线程访问同步块时，锁会被升级为轻量级锁。 轻量级锁使用CAS操作尝试将对象头中的锁记录指针替换为指向锁记录的指针。 如果CAS操作成功，表示线程获取了轻量级锁，并可以进入同步块执行。 如果CAS操作失败，表示存在竞争，锁会膨胀为重量级锁。 重量级锁（Heavyweight Locking）： 重量级锁是传统的锁实现，使用互斥量来实现线程同步。 当多个线程竞争同一个锁时，轻量级锁会膨胀为重量级锁。 被锁住的对象会进入等待队列，非锁定的线程会被阻塞。 线程释放锁后，等待队列中的线程会通过操作系统的唤醒机制被唤醒，竞争锁的所有线程抢夺锁的所有权。 Java锁升级的过程是动态的，根据竞争情况进行自适应调整。在并发度不高的情况下，偏向锁和轻量级锁可以减少不必要的竞争，提高性能。而在高并发情况下，锁会升级为重量级锁，确保线程安全性。锁升级过程是由JVM自动完成的，开发人员无需显式介入。 参考： 锁升级：无锁、偏向锁、轻量级锁、重量级锁 ","link":"https://tangwan.github.io/post/java-suo-sheng-ji-yuan-li/"},{"title":"Java ArrayList扩容原理","content":"Java中的ArrayList是基于数组实现的动态数组，它会在需要时进行自动扩容。下面是ArrayList的扩容原理： 初始容量： 创建一个ArrayList对象时，会为其分配一个初始容量（默认为10）的数组。 添加元素： 当向ArrayList中添加元素时，会先检查当前数组是否已满。 如果数组已满，则会触发扩容操作。 扩容操作： 扩容操作会创建一个新的更大容量的数组，并将原数组中的元素复制到新数组中。 扩容大小的计算方式通常是使用原数组大小 * 1.5（Java 7之前）或原数组大小 * 1.2（Java 7及以后）。 使用Arrays.copyOf()方法将元素从旧数组复制到新数组。 扩容完成后，ArrayList内部使用新的数组替换旧的数组。 容量增加： 扩容后，ArrayList的容量会增加，但其中的元素数量并未改变。 ArrayList内部有一个字段size来记录当前元素的数量。 由于扩容涉及数据的复制，因此频繁的扩容操作可能会导致性能下降。为了避免频繁扩容，可以在创建ArrayList时指定一个较大的初始容量，以减少扩容的次数。 需要注意的是，ArrayList并不是线程安全的，如果在多线程环境下使用ArrayList，需要通过外部同步手段来保证线程安全。或者可以考虑使用Vector或CopyOnWriteArrayList等线程安全的替代方案。 ","link":"https://tangwan.github.io/post/java-arraylist-kuo-rong-yuan-li/"},{"title":"MySQL安装配置","content":"下载MySQL安装包 官网最新版下载地址 https://dev.mysql.com/downloads/mysql/ 官网历史稳定版下载地址 https://downloads.mysql.com/archives/community/ 选择对应的系统和版本安装包下载即可 安装 Windows 如果下载的是.exe或.msi文件,双击安装,下一步--&gt;下一步即可,把MySQL安装未系统服务,在服务管理界面设置开机启动即可. 如果下载的是压缩包,使用解压缩软件解压,然后把解压的文件夹移动到自己想放的目录(避免放在中文文件夹下面),然后执行下面命令添加为系统服务 cmd&gt; mysqld --install Mysql5.6 #将mysql安装到服务列表,Mysql5.6为服务名称,随意取名 cmd&gt; net start mysql5.6 #启动服务 cmd&gt; mysql -uroot -h 127.0.0.1 -p #尝试连接mysql cmd&gt; mysqld --remove Mysql5.6 #删除mysql服务 cmd&gt; net stop mysql5.6 #停止服务 cmd&gt; mysqld --install-manual #改为手动启动服务 Mac $ brew update $ brew search mysql $ brew install mysql@5.6 # mysql加入到path,本机就可以 $ vim ~/.bash_profile export PATH=&quot;/usr/local/opt/mysql@5.6/bin:$PATH&quot; $ source ~/.bash_profile Linux yum或apt-get配置正确的国内yum源或apt-get下载源,直接安装,遇到问题谷歌百度搜一下这里不再介绍 安装MySQL.xxx.tar.gz docker 首先自行安装docker和docker-compose 使用docker-compose用官方mysql镜像来启动一个mysql容器 具体mysql官方有哪些镜像标签,到这里去看 https://hub.docker.com/_/mysql version: &quot;3&quot; services: mysql: image: mysql:5.7 container_name: mysql5.7 restart: always ports: - 3306:3306 volumes: # 把宿主机目录挂载到mysql data目录,持久化数据数据,容器重启或重建数据不丢失 - /data/mysql/db_data:/var/lib/mysql # 把自己的my.cnf配置文件放到挂载的宿主机目录可以替换掉默认的配置 - /data/mysql/config:/etc/mysql/conf.d:ro environment: #默认只能创建一个库,如果想在一个容器创建多个数据库需要修改官方Dockerfile重新build镜像,比较麻烦,还是启动后自己用SQL来建库比较方便 - MYSQL_DATABASE=mydb # 指定一个普通用户和密码 - MYSQL_USER=test - MYSQL_PASSWORD=123456 # 设置root密码 - MYSQL_ROOT_PASSWORD=654321 我的my.cnf配置文件 #修改MySQL服务器编码utf8mb4 [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8' #区分大小写(默认区分),最好别修改默认值 #unix下lower_case_table_names默认值为0 ,Windows下默认值是1 ,Mac OS X下默认值是2 #lower_case_table_names=2 ###############################MySQL 服务器 my.cnf优化配置################################# ##开启慢查询1.开启,0.关闭 slow_query_log=1 #查询时间300ms以上的会记录到文件 long_query_time=0.3 #慢查询日志记录位置 slow-query-log-file=/var/log/mysql/slow.log #记录未用到索引的查询 log-queries-not-using-indexes #慢查询日志存储方式,默认FILE,可以只是用一个,也可都使用,存储在mysql.slow_log表中 log_output='FILE,TABLE' #不再进行反解析（ip不反解成域名），这样可以加快数据库的反应时间。 skip-name-resolve #跳过授权,可用来重置root密码 #skip-grant-tables #最大连接数 max_connections=1000 #MySQL的连接数据达到 max_connections时,新来的请求将会被存在堆栈中,堆栈保存连接请求数量 back_log=256 #服务器关闭非交互连接之前等待活动的秒数.默认28800秒（8小时);改为24小时 wait_timeout=86400 #服务器关闭交互式连接前等待活动的秒数。参数默认值：28800秒（8小时）;改为24小时 interactive_timeout=86400 #指定索引缓冲区的大小,默认4M;修改为256M key_buffer_size=268435456 #随机读缓冲区大小,设置为16M read_rnd_buffer_size=16773120 #每个需要进行排序的线程分配该大小的一个缓冲区;默认数值是2097144(2M)，可改为16777208 (16M) sort_buffer_size=16777208 #联合查询操作所能使用的缓冲区大小 join_buffer_size=16777208 #通过设置tmp_table_size选项来增加一张临时表的大小 tmp_table_size=128M #可以复用的保存在中的线程的数量 thread_cache_size=80 #推荐设置为服务器 CPU核数的2倍 thread_concurrency=20 #InnoDB使用该参数指定大小的内存来缓冲数据和索引 innodb_buffer_pool_size=1G innodb_file_io_threads=4 #log缓存大小，一般为1-8M，默认为1M，对于较大的事务，可以增大缓存大小。 innodb_log_buffer_size=8M ##存放文件大小限制 max_allowed_packet = 16M ##########################EOF################################################################ [mysql] default-character-set=utf8mb4 [client] default-character-set=utf8mb4 ","link":"https://tangwan.github.io/post/mysql-an-zhuang-pei-zhi/"},{"title":"kubernetes常用命令","content":"常用命令 # 查看k8s集群节点简单信息 $ kubectl get nodes # 查询k8s集群节点详细信息 $ kubectl get nodes -o wide # 查看k8s集群更详细的信息 $ kubectl describe nodes # 查询k8s集群所有namespace $ kubectl get ns $ kubectl get namespace $ kubectl describe namespace # 创建namespace,名称为dev $ kubectl create namespace -name dev # 删除namespace (如果namespace下面有pods,需要先删除namespace下pods) $ kubectl delete namespace dev # 以下命令不带-n参数指定namespace,默认都在default这个namespace下执行 # 创建一个nginx服务,副本数量3 $ kubectl create deployment nginx-app --image=nginx --replicas=3 # 查看此deployment状态,READY 3/3 标识3个副本均启动完成 $ kubectl get deploy nginx-app # 进入deployment的任一pod终端,使用curl访问 $ kubectl get pods $ kubectl exec -it nginx-app-d6ff45774-8wb5t -- /bin/sh # 在pod中执行非交互式命令 $ kubectl exec nginx-app-d6ff45774-xm6bm -- cat /etc/hostname # 查看是否返回nginx首页 $ curl localhost $ exit # 创建service,暴露deployment的服务供外部访问,随机生成NodePort端口,--target-port=8000容器端口 $ kubectl expose deployment nginx-app --port=80 --type=NodePort --name=nginx-http $ # 查看创建的service端口,使用浏览器访问nodeIp:此端口可以看到nginx页面,多次访问,请求随机落到3个副本上 $ kubectl get svc nginx-http # 查看指定pod的滚动日志 $ kubectl logs -f nginx-app-d6ff45774-xm6bm # 查看deployment,service,pods并删除 $ kubectl get svc $ kubectl get deploy $ kubectl get pods $ kubectl delete svc nginx-http $ kubectl delete deploy nginx-app $ kubectl delete pods nginx 发布一个nginx服务 创建 nginx-pod.yml nginx-deployment.yml nginx-svc.yml 三个yml配置文件,三个配置文件内容也可以写在一个yml中 nginx-pod.yml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx:alpine ports: - containerPort: 80 nginx-deployment.yml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:alpine ports: - containerPort: 80 nginx-svc.yml apiVersion: v1 kind: Service metadata: name: nginx-service spec: selector: app: nginx ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30080 type: NodePort 使用配置文件定义服务发布服务 # 发布pod到指定的namespace $ kubectl apply -f nginx-pod.yml -n dev $ kubectl apply -f nginx-deployment.yml -n dev $ kubectl apply -f nginx-svc.yml -n dev $ kubectl get deploy -n dev $ kubectl get svc -n dev # 本机浏览器访问http://nodeIp:30080,能看到nginx欢迎页就代表服务启动没有问题 # 查看副本数量 $ kubectl get rs # 手动扩缩容 $ kubectl scale deploy nginx-deployment --replicas=4 -n dev # 自动扩缩容,cpu使用率达到80%,最小副本数量10,最大扩容数量15 $ kubectl autoscale deploy nginx-deployment --min=10 --max=15 --cpu-percent=80 # 查看自动扩缩容配置 $ kubectl get hpa # 删除自动扩缩容配置 $ kubectl delete hpa nginx-deployment # 删除deployment和service $ kubectl delete -f nginx-deployment.yml -n dev $ kubectl delete -f nginx-svc.yml -n dev http://docs.kubernetes.org.cn/683.html 如果不知道命令用法可以加参数 --help查看帮助文档 ","link":"https://tangwan.github.io/post/kubernetes-chang-yong-ming-ling/"},{"title":"RabbitMQ常见问题和答案","content":"以下是一些关于RabbitMQ的常见面试问题及其答案： 什么是RabbitMQ？ RabbitMQ是一个开源的消息中间件，它实现了AMQP（高级消息队列协议）并提供可靠的消息传递机制。 RabbitMQ的主要特点是什么？ RabbitMQ具有以下主要特点： 灵活的消息路由机制 可靠的消息传递机制 支持多种消息模式（点对点、发布/订阅、请求/响应等） 内置的消息持久化机制 高可用性和可扩展性 RabbitMQ中的交换机（Exchange）是什么？ 交换机是RabbitMQ中用于接收发布的消息，并将其路由到一个或多个队列的组件。它根据消息的路由键（Routing Key）和绑定键（Binding Key）来确定消息的路由方式。 RabbitMQ中的队列是什么？ 队列是RabbitMQ中用于存储消息的组件。消息通过交换机路由到队列，并可以按照FIFO（先进先出）的顺序进行消费。 RabbitMQ中的绑定是什么？ 绑定是交换机和队列之间建立关联关系的过程。绑定使用绑定键（Binding Key）来指定交换机将消息路由到哪些队列。 RabbitMQ中的消息确认机制是什么？ 消息确认机制用于确保消息在发送和接收过程中的可靠性。生产者发送消息后，可以选择等待消费者的确认（ACK）才认为消息发送成功。 RabbitMQ中的持久化是如何实现的？ RabbitMQ提供了消息持久化机制，即使在RabbitMQ服务器重启后，也能保留已经发布的消息。通过将交换机和队列设置为持久化，以及在发布消息时将消息标记为持久化，可以实现消息的持久化存储。 RabbitMQ如何处理消息的优先级？ RabbitMQ本身不直接支持消息优先级。但可以通过使用多个队列来实现消息的优先级处理，每个队列处理不同优先级的消息，然后消费者按照优先级顺序从不同队列中消费消息。 这些问题涵盖了RabbitMQ的一些基本概念和特性。在面试中，可能会进一步深入探讨这些概念以及如何在实际场景中使用RabbitMQ。 ","link":"https://tangwan.github.io/post/rabbitmq-chang-jian-wen-ti-he-da-an/"},{"title":"SpringBoot ApplicationRunner或者CommandLineRunner区别","content":"ApplicationRunner和CommandLineRunner是Spring Boot中用于在应用程序启动后执行特定代码的接口。 ApplicationRunner接口： ApplicationRunner是一个函数式接口，它定义了一个run()方法。 run()方法在Spring Boot应用程序启动后被调用，可以用于在应用程序完全启动之后执行一些初始化任务或逻辑。 ApplicationRunner的run()方法接收一个ApplicationArguments对象作为参数，该对象包含启动应用程序时传递的命令行参数。 CommandLineRunner接口： CommandLineRunner是一个函数式接口，也定义了一个run()方法。 run()方法在Spring Boot应用程序启动后被调用，用于执行一些初始化任务或逻辑。 CommandLineRunner的run()方法接收一个String数组作为参数，该数组包含启动应用程序时传递的命令行参数。 区别： 参数类型不同：ApplicationRunner的run()方法接收一个ApplicationArguments对象，而CommandLineRunner的run()方法接收一个String数组。 ApplicationRunner提供了更丰富的功能，因为ApplicationArguments对象不仅包含了命令行参数，还包含了其他有关应用程序上下文的信息，如配置属性等。 一般情况下，如果只关心命令行参数，可以使用CommandLineRunner接口；如果需要更多关于应用程序上下文的信息，可以使用ApplicationRunner接口。 无论选择哪个接口，您可以通过实现相应的接口并将其作为@Component或@Bean注解添加到Spring Boot应用程序中，以便在应用程序启动后执行相关逻辑。 ","link":"https://tangwan.github.io/post/springboot-applicationrunner-huo-zhe-commandlinerunner-qu-bie/"},{"title":"代理模式的Java例子","content":"下面是一个用Java写的代理模式的例子： 首先，定义一个接口Image，表示图像的操作： public interface Image { void display(); } 然后，实现该接口的具体类RealImage，表示真实的图像操作： public class RealImage implements Image { private String filename; public RealImage(String filename) { this.filename = filename; loadImageFromDisk(); } private void loadImageFromDisk() { System.out.println(&quot;Loading image from disk: &quot; + filename); } @Override public void display() { System.out.println(&quot;Displaying image: &quot; + filename); } } 接下来，定义一个代理类ProxyImage，用于控制对真实图像的访问： public class ProxyImage implements Image { private String filename; private RealImage realImage; public ProxyImage(String filename) { this.filename = filename; } @Override public void display() { if (realImage == null) { realImage = new RealImage(filename); } realImage.display(); } } 最后，在客户端中使用代理模式： public class Client { public static void main(String[] args) { Image image1 = new ProxyImage(&quot;image1.jpg&quot;); Image image2 = new ProxyImage(&quot;image2.jpg&quot;); // 图像1的加载和显示 image1.display(); // 图像2的加载和显示 image2.display(); // 图像1已经加载过，直接显示 image1.display(); } } 输出结果： Loading image from disk: image1.jpg Displaying image: image1.jpg Loading image from disk: image2.jpg Displaying image: image2.jpg Displaying image: image1.jpg 在这个例子中，RealImage表示真实的图像操作，ProxyImage作为代理类控制对RealImage的访问。 当需要显示图像时，如果图像还没有加载，则由ProxyImage负责加载图像，然后通过RealImage显示图像。如果图像已经加载过，ProxyImage直接调用RealImage显示图像，避免了重复加载。 ","link":"https://tangwan.github.io/post/dai-li-mo-shi-de-java-li-zi/"},{"title":"Mac的主机名为bogon原因和解决办法","content":"原因: 在使用IntelliJIDEA和terminal工具时,主机名显示为bogon(虚拟).这是因为终端会首先向DNS查询本机IP对应的主机名,查询不到才会显示我们自己设置的主机名,而由于我们配置或默认的DNS错误地将保留地址反向的NS查询结果返回了bogon. 其中bogon本应该用来指虚假的IP地址,而非保留IP地址.因此就出现了会时不时地打印bogon这种奇怪名字作为计算机名的现象了. 解决: 让终端直接显示我们的主机名而不是从DNS查询即可显示正确的主机名,请替换你的主机名为你想要设置的主机名,使用英文字母不要带空格例如:Devin-MBP. $ sudo hostname 你的主机名 $ sudo scutil --set LocalHostName 你的主机名 $ sudo scutil --set HostName 你的主机名 补充一点: 设置电脑名称,别人可以在局域网看到此电脑名称,设置&gt;共享&gt;电脑名称==&gt;输入即可,也可以使用下面的命令行修改. $ sudo scutil --set ComputerName 你的主机名 #设置电脑名称,别人在网络共享上可以看到这个名字 ","link":"https://tangwan.github.io/post/mac-de-zhu-ji-ming-wei-bogon-yuan-yin-he-jie-jue-ban-fa/"},{"title":"单例模式之懒汉式和饿汉式","content":"懒汉式单例模式 public class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 饿汉式单例模式 public class Singleton { private static Singleton instance = new Singleton(); private Singleton() {} public static Singleton getInstance() { return instance; } } ","link":"https://tangwan.github.io/post/dan-li-mo-shi-zhi-lan-han-shi-he-e-han-shi/"}]}